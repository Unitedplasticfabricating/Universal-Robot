Robot project journal
Started: Monday 6/10/2024
By: Calvin

Monday I worked on assembling everything except the robot itself. I physically mounted the UR controller box, the MachineMotionV2, the robot safety module, and the emergency stop. To do this I had to take all the boxes apart and find the screws, allen wrenches, 
No instructions. No wiring diagram
Had to wire all the shit together. Screwdriver
Found weights to counterbalance
Got the robot mounted on with a forklift
Needed to know that my ip address wasn’t going to be in the pool of florida ip addresses
Robot safety module was preventing the lift column from operating so I removed that
Installed the urcap software via the usb drive onto the ur
Linked machinemotion and ur via static ip addresses and ethernet cable. 
I learned that program files are saved as program files on the pendant.
I learned that installation setups are saves as installation files on the pendant. If you plug in a usb into the pendant, I think you can transfer files into or out of the ur.
I think you don’t need the vention usb inserted into the pendant to access urcap functionality. It installs the program on the pendant itself and connects via the ethernet cable and staticip.
I got the robot oriented correctly in virtual 3D space, saved it as default.installation, backed it up onto flash drive, and saved it to github. 
I calibrated the TCP and payload for a robot with no end effector. 
Reminder: On page 125 of the manual, it talks about Manual Mode vs automatic mode. Manual Reduced Speed is the default. I need to figure out how to switch to Manual High Speed and have it set to do that as the default. 
Reminder: Installation -> Safety -> Tool Position has a warning symbol. I need to read section 1.24 in the manual Software Safety Configuration to figure out what the warning is. 
Reminder: set the Home position
Software Safety Settings. Password is plastic
Discovered joint limits for every axis is 363 degrees to -363. So, almost two full rotations around. The maximum speed for each joint in “Normal” or “Reduced” mode is 131 degrees per second, or 221 degrees per second for the wrist joints. 161 for elbow. So far, the robot has not come close to that speed. 
I was able to do a full backup of the robot. I went to the pendant’s hamburger menu -> settings -> backup restore or whatever. I gave a huge .urb file, which I think included the entire operating system of the robot, not just programs, installations, and variables. I was able to push this file into fork on the local branch, but I couldn’t push it to github because the file size was too large. So, I “Reset main to here” in fork to remove that commit. The file is one folder up in the “C:\Users\cbaumgartner\Documents\UPF source code”. 
I successfully made a square motion program!
I tried to make a peg welding program but received an error. Joint acceleration failed to pass sanity check. I think it’s because I tried to do a MoveL directly over the base. Anyways it errored and locked me out. When I try to restart the robot (safety system), (the 5 step process), when it releases the brakes it keeps erroring. It says “Fault: Robot cannot maintain its current position. Check if payload is correct”. Weird. 
The urp files are all gibberish, the ones I made myself. It looks like the original ones like the one that came preinstalled on the robot contain xml like structures, but the ones I made are compressed. 
I installed python to make a script to decompress those files. 

Big breakthrough
I talked to Luca from vention. For the robot stopping and faulting, we figured that out. I set the payload to 0.o kg (down from 1.3). That was what was breaking the program, that it was off by 1 kg. Sometimes the payload wizard in UR is not very accurate. So he recommends weighing the payload and getting that exact by hand and entering it in. For the payload center of gravity and the tcp position, you can use the wizard. 
He agrees with me that the initial breakage was caused by using a moveL in a large movement over the base. moveL should only be for smaller movements or movements that you know aren’t going to be too close to singularities. After changing the payload to 0, I ran the same program (with the moveL). The program stopped because it said “cannot achieve the requested position” or something like that. However, it did not power off the robot. I just hit enable and had to angular move the joints manually (fourth tab) to get myself out of the knot. 
Next, I set up the urcap. My computer was not connecting to the machinemotion at 192.168.7.2. Luca emailed me directions for how to set up the urcap connection to allow the robot to control the lift column. I called justin to get the connection working. 
Computer was not connecting to 192.168.7.2 in chrome. What I had to do was unplug my ethernet cable from both sides. Turn off machinemotion. Unplug machinemotin’s power cqable. Hold down its power button for 20 seconds to release any stored energy in capacitors. Then turn it back on. After this, my Ethernet – Network 3 icon in control panel -> network and internet -> network connections changed from no connection to ethernet. And going to the chrome ip worked. 
Next, I wanted to get it so the robot could control the lift column. I went to http://192.168.7.2/networkConfig. Under ethernet settings, I clicked LAN1 which is where the cord is plugged into. I set that to 192.168.3.52. Justin had to look in dhcp to find one in our network that wasn’t being used, because I don’t have that permission anymore. He then said he reserved that ip for me. 
Then I went into UR settings on the pendant and changed the robot’s ipaddress to 192.168.3.53, which was also available. Justin also reserved this for me. I then went into installation->urcaps and configured it to be 192.168.3.52. and saved the configuration. 
I then created a new program to test whether the urcap works. It does! When I played my program in automatic mode, it did raise thelift column by 10mm (which I specified). 
Also, when I clicked the UR+ button and jogged it, it did raise the lift column as well. 
The UR+ button only works when in automatic mode, or it does work in manual mode but only when you have the 3pe button pressed. If youre in automatic mode and jog the column, then switch to manual mode, the column will continue its jog but then will not take any more inputs unless the 3pe is pressed. You can hold the 3pe, press the jog button, wait for the column to start moving, and then let go of the button. It will finish its move. 
Reminder: you should figure out a way to change the settings so that you don’t have to hold the 3pe even in manual mode because that’s annoying. OR find out how to enable everything from automatic mode

I switched my journal to a txt document so i could copy into repo easier and see the changes. If i want to make it pretty i can always copy the text into a word doc. 

I completed copyfilesintorepo.py which is sweet. i plug in the flash drive, run that program, and commit fork. super easy to source control all my changes on the UR. 

Programs can be saved as files and run as a subprogram. To do this, start editing the main toplevel program. Click robot program. Click SubProg. Under subprogram file, select your file. This will open the file as a subprogram. 
By default, making changes to this subprogram will not affect the parent file. 
By default, making changes to the parent subprogram will not affect the loaded subprogram. 
If you want to change a subprogram, you can change the parent subprogram and save. then go into the parent program, loaded subprogram, and reload to pull the changes. 

How to enter freedrive mode mid program:
You can look at using the “freedrive_mode” script call to set the robot into freedrive mode and the corresponding “end_freedrive_mode” call to stop it. You can look at the URScript manual for understanding both of these functions.
In your case you could possible set up a thread that watches the digital input for enable/disabling the freedrive mode.
https://forum.universal-robots.com/t/open-and-close-the-freedrive-switch-while-the-program-is-running/18046/2

save tcp pose as a variable: https://forum.universal-robots.com/t/creating-a-variable-waypoint/19366

the types of variables are: bool, int, float, string, pose, list (page 163). 

I need to learn about rotation vectors in UR. i want to align my tcp perpendicular to a cardinal plane. But i have no idea how rx, ry, and rz work or what they mean. 
Apparently (according to the internet), UR uses axis-angle representation of rotation vector (opposed to RPY roll-pitch-yaw. I don't know what that is either). 

Coordinates/directions:

Feature: view. this is when i aligned the robot with the direction i wanted it to face
Rx=0, RY=0, Rz=0 is with the tcp pointing straight up
The x direction is straight out in front of the robot. specifically, -x.
the y direction is to the right. positive y is right. negative y is left

Feature: Base. this is the preset orientation of the robot. in this view, pushing the forward button makes the robot come back towards me at an angle
Rx=0, RY=0, Rz=0 is with the tcp pointing straight up


I watched some good courses on virtual reality and representation of 3d space by this guy from University of Illinois at some IIT school. I learned different representations of orientation in 3d space. 
1. Euler's yaw, pitch, roll with respect to airplanes (commutative, respect to horizon, not uniform especially when approaching vertical)
2. Euler's yaw, pitch, roll with respect to fixed cartesian axes. (not commutative)
Axis angle representations: length of v is 1 (unit vector). 
3. axis-angle representation in Exponential syntax 
	[(v1, v2, v3), theta] -> (v1*theta, v2*theta, v3*theta)
4. axis-angle representation in Quaternion syntax
	[(v1, v2, v3), theta] -> (cos(th/2), v1*sin(th/2), v2*sin(th/2), v2*sin(th/2))
	
Based on that info i came back and ran the robot in Base mode. Here the buttons are labelled. 

zeroing out all the Rx, ry, rz made the robot point straight up. 
pressing each button worked the same as rx:
	i press rx and the tool moves. Imagine an axis through the tcp parallel to the fixed cartesian x axis. The tool rotates around that axis. I then send the tool back home.
	while i am going, ry and rz values remain at 0. 
	rx value increases consistently, hitting .785 when the robot has rotated 45 degrees, 1.57 when the robot has rotated 90 degrees. 
going back to 0,0,0 rotation and using the other buttons worked the same way. they rotated the tcp about their axis. 
entering a value of 7 resulted in a value of .717 (7 - 2 pi)
crossing the 6.28 barrier manually moving results in the angle dropping back down to 0.01

next experiment:
i set the tool orientation to 0,0,0
i rotated rx to +.785 using the rx+ button. 
i then pressed the ry+ button. it rotated the tcp with respect to the y axis. not only did the ry value change as i went, the rx value changed as well. so did the z value. 
rx decreased to -.741, ry went from 0 to .760, rz went from 0 to -.318

Based on this, I hypothesize that the rx, ry, and rz values in the upper right corner (orientation coordinates) are defined using axis-angle representations in Exponential syntax. 

I also hypothesize that pressing the rx+, ry+, etc. buttons do not simply increase the rx coordinate and calculate the resulting position. 
	They send a small increment of a transform about the x axis (something like a (0.1, 0, 0) transform vector and calculate the resulting exponential syntax of that transform. 
	This is why the other values sometimes change when you give a simple ry+ command. 
	so, holding down the ry+ button will make the robot perform a rotation about the y axis. But a rotation about the y axis most likely will change all 3 values in exponential syntax. 
	
You can set the rotation vectors to (90deg, 90, 0) or (.785, .785, 0). It looks like it's pretty close to a 45 degree rotation in both the x and y axis but i'm not sure. 
An example of this is that I set rx = 90deg (1.57), ry = 90deg (1.57), rz=0. it found the position. 
	the robot was pointed slightly down and at an angle. it was not orthogonal to any of the major axes. 
	however, projecting onto the x-y plane, the robot was at a 45 angle to the major axes. 
	this only makes sense if you understand axis-angle representaion with Exponential syntax. 
	
I need to make a list of the common orthogonal positions and common 45 (45 degrees with respect to one plane, ortho/parrallel with respect to the final axis) positions and their Exponential representation
	so that i can quickly position my robot in that orientation at a given position. 


I need to learn how to combine the position coordinates of a stored position (x,y,z) with manually setting the orientation coordinates. Maybe could be pose_add(), pose_sub(), or pose_trans(). 
update: they are hard to understand
look up how to manually enter poses
they used pose_trans() with a p[0,height,0,0,0,0] to manually tell it to go up height meters. 
https://www.universal-robots.com/articles/ur/programming/moving-to-a-position-calculated-from-user-input/
ill look up how to create my own function . cant

coordinate system:
i found out that the X+ direction is out away from the base. forward

for homing, use a tcp on the side of the gun. if the gun is attached sideways, then have a "rubber tip" "through" the gun (parrallel to robot arm). 
set this as a separate tcp in installation, and call the homing commands using that tcp.

the homing program wasnt working because of how the test box was mountd on the table. when it was homing on the bottom face, it was hitting into the table and faulting. 
i looked at the station in the express cell line and this isn't going to be a problem out there.
we are going to change the attachment of the test box to the table. in the mean time, i will adjust my program to avoid the table. 

i made a Main Method, and put test teach position into it. the thread that was part of test teach position did not come. running the program did not put the robot into freedrive mode at the correct time. 
copying over the variables setup and the thread into Test Main Program did make the program work. 

god damn it. 
it doesnt like nested subprograms.
i have some programs for aligning the tcp with a cardinal direction. 
my program corner homing brb contains calls to those alignment subprograms
i tried to put corner homing brb into my main program as a subprogram. robot didnt like that. 
it said 'the subprogram contains one or more calls to other subprograms. open corner homing brb and remove any contained subprograms, save, and then try again to add it.'
https://forum.universal-robots.com/t/subroutine-within-subprogram/12634 says you can do it as a subroutine, as a subprogram within a script block, or as a user-defined function

i added the plate to the robot end and added a tcp and payload into the system. 
when i set those as the active payload, the robot does some weird stuff when running the program. it bonks into itself when trying to align left

work on one corner. perfect that. and move the robot roll wheels to each corner on the tank.

want to reorientate the robot on the stand. everything is opposite
right now the cord is pointing left (when looking WITH the robot). we want the cord pointing right
robot reoriented with forklift

i learned you can use breakpoints in the software.
i learned that a subroutine is just a call to a subprogram.
script commands can be done using a single line or via a file
i need to try out this file script editor. 

i got the robot to follow the path on both sides, but when it goes around the corner, the angle dips. it does not maintain level orientation. 

maybe i need to do a "circle move" as part of a moveP command while welding and going across the corner. 

i try making a test circle move program out in space. it does not work very well. 
when the orientation switches from left to forward, the arm does a weird swivel to orient itself. it seems like an unnecessary swivel. when i use those points in the program of a moveP, the robot faults out. 
it is trying to maintain its speed (a pretty slow speed), but it needs to rearrange its joint angles to move just the slightest in tcp. 
i believe this is called approaching a singularity

i set a position by manually rotating the joints (instead of using the Move screen's rz+) and that did result in the robot not doing its weird dip. 
but it faulted because it needed to move at a constant speed and the distance was super small and the direction change was a lot.

motherfucker i dropped the speed down from 250 to 20 on the entire path.
it went so slow on the straight part, "sped up" a little on the curved part and then partway through the curved section stopped. 
warning: sanity check
protective stop: path sanity check failed: sudden stop
i will try ensuring that the three points on the path for a smooth curved
6.35 mm = .25 inches

rx,ry,rz patterns:
i go to align_left, then spin the head manually with Move Rz+ to a 45 degree angle. During this time, the ry and rz values go from 0 and go up. they are always equal.
i need to figure out what the angle is for align forward/left 45 degrees

it looks like th script feature in the robot does python but doesnt do tuples. damn. 

i need to calculate the midpoint of the arc turning around the corner
https://math.stackexchange.com/questions/4694976/calculate-length-between-intersection-of-circle-and-2-tangent-lines-relative-to

i got a program going. it goes smoothly through p2. but it stops at p2 (i put a breakpoint) and the center of the tcp is still 1.25" short of the end of the box
super weird. could my intersection calculations be off?

i added popups to the program so i can see what the coordinates are for all the points its calculating
i plotted the points and the points look fine
lucas took a video for me while i was performing the circle move. the tcp (end of robot) is in contact with the box and thats why it stops. 
BUT its supposed to be in contact with it. in the video, you can see the robot performing the desired motion. 
It is not "trying to go through" the box as much as it is just sliding around the corner of the box
so, the contact here is good. I don't need to change the motion, I need to tell the robot to not Fault out when it feels contact
I think i can achieve this by adding a force effect
additionally, after faulting out, i clicked Enable and continued the motion and it worked as intended, went to its desired position point 3

I made a test program to test whether the Force command actually worked
i set two waypoints a few mm off the side of the box, and moveP'd the robot from one point to the other. the robot did not touch the box
I then put that move command inside a Force command of 5N. It now touched the box and i couldnt fit a piece of paper or plastic in between the toolhead and the box while it was running

adding the force command to the main program still results in a protective stop while rounding the corner. i wll try specifying the tcp and also trying a larger newton value.
another thing to consider if this doesnt work is temporarily turning down the protective stop sensitivity, hopefully just while performing that force move

found a video on protective stops: https://video.universal-robots.com/tech-talk-understanding-protective
faults, violations, and protective stops are the three ways the robot can stop due to itself observing that something is wrong
a protective stop is issued when the robot can no longer perform the intended motion
a violation is when a safety system observes that a safety limit is exceeded
a fault is when the safety system detects a fault in the hardware or software
a torque window is the amount of current the robot expects to use in order to accomplish the necessary motion. if it needs more than that (outside the window), this is an indcator that the robot is blocked by someone or something.
"scaling" is lowering the acceleration for normal payloads or heavier payloads. 

i will try changing the variable in the program to .03 inches (a 32nd of an inch) down from 0.25 inches, so that it doesn't try to go into the box
I got rid of the radius and changed the rotation command from a moveP to a speedl() in script. 
when i do it in the main program, it sometimes gets singularity errors
it sometimes gets protective stops because point2 is stopping too early and turning into the box. but when i look at the intersection point, it is accurate
i figured out one of the problems. i switched the moveP from p1 to p2 into a moveL, and now it stops at the correct point. 
I believe it was stopping early before it got to point 2, because of a blend radius (25 mm = 1 inch). that would explain why it was stopping one inch too short. 
the singularity thing is still there when i do the speedl() command

I figured out why the singularity is happening. 
when all 4 axes are aligned, this is an example of a singularity. when it spins from the first edge to the second edge, it passes through a position where all 4 robot axes are aligned. 
i think the robot can make it through this position if it is part of a move command, but stops if it is part of a speedl() command or a manual move (fourth tab on pendant).
i have a video from july 30 where the robot is performing the "around the corner" motion in space, and it hits the singularity, drops its wrist below (which interrupts the motion), but then continues on. 

